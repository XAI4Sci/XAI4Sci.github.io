<!DOCTYPE HTML>
<!--
	Prologue by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>XAI4Sci: Explainable machine learning for sciences</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<div id="header">

				<div class="top">

					<!-- Logo 
						<div id="logo">
							<span class="image avatar48"><img src="images/ai.jpg" alt="" /></span>
							<h1 id="title">Jane Doe</h1>
							<p>Hyperspace Engineer</p>
						</div> -->

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="#top" id="top-link"><span class="icon solid fa-home">Home</span></a></li>
								<li><a href="#about" id="about-link"><span class="icon solid fa-info-circle">About</span></a></li>
								<li><a href="#schedule" id="schedule-link"><span class="icon solid fa-calendar">Schedule</span></a></li>
								<li><a href="#papers" id="papers-link"><span class="icon solid fa-newspaper">Call for papers</span></a></li>
								<li><a href="#organizers" id="organizers-link"><span class="icon solid fa-users">Organizers</span></a></li>
							</ul>
						</nav>

				</div>

				<div class="middle">
				
					<h5><font color=#999999> Important dates:</font></h5>

					<p style="font-size: 18px; color: #999999">Submission Deadline:<br>November 24, 2023, 23:59 <a href="https://www.timeanddate.com/time/zones/est">EDT</a></p>
					<p style="font-size: 18px; color: #999999"">Review Deadline:<br>December 6, 2023, 23:59 <a href="https://www.timeanddate.com/time/zones/est">EDT</a></p>
					<p style="font-size: 18px; color: #999999"">Author notification:<br>December 11, 2023</p>
					<p style="font-size: 18px; color: #999999"">Workshop:<br>TBD</p>

				</div>
				
				<div class="bottom">

					<!-- Social Icons 
						<ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
							<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
							<li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						</ul> -->

				</div>

			</div>

		<!-- Main -->
			<div id="main">

				<!-- Intro -->
					<section id="top" class="one dark cover">
						<div class="container">

							<header>
								<h2 class="alt strong">XAI4Sci: Explainable machine learning for sciences</h2>
									<!-- <span class="image avatar48"><img src="images/ai.jpg" alt="" /></span> -->
							<!-- <p>Ligula scelerisque justo sem accumsan diam quis<br />
								vitae natoque dictum sollicitudin elementum.</p> -->
							</header>

						</div>
					</section>

				<!-- About -->
					<section id="about" class="two">
						<div class="container">

							<header>
								<h2>About</h2>
							</header>

							<p>As the deployment of machine learning technology becomes increasingly common in applications of consequence, 
							such as medicine or science, the need for explanations of the system output has become a focus of great concern. 
							Unfortunately, many state-of-the-art models are opaque, making their use challenging from an explanation standpoint, 
							and current approaches to explaining these opaque models have stark limitations and have been the subject of serious
							criticism.</p>

							<p>The <i>XAI4Sci</i> workshop aims to bring together a diverse community of researchers and practitioners working at 
							the interface of science and machine learning to discuss the unique and pressing needs for explainable machine learning 
							models in support of science and scientific discovery. These needs include the ability to (1) leverage machine learning 
							as a tool to make measurements and perform other activities in a manner comprehensible to and verifiable by the working 
							scientists, and (2) enable scientists to utilize the explanations of the machine learning models in order to generate 
							new hypotheses and to further knowledge of the underlying science.</p>

							<p>The <i>XAI4Sci</i> workshop invites researchers to contribute short papers that demonstrate progress in the development 
							and application of explainable machine techniques to real-world problems in sciences (including but not limited to, 
							physics, materials science, earth science, cosmology, biology, chemistry, and  forensic science). The target audience 
							comprises members of the scientific community interested in explainable machine learning and researchers in the machine 
							learning community interested in scientific applications of explainable machine learning. The workshop will provide a 
							platform to facilitate a dialogue between these communities to discuss exciting open problems at the interface 
							of explainable machine learning and science. Leading researchers from both communities will cover state-of-the-art 
							techniques and set the stage for this workshop.</p>

							<h3>AAAI</h3>
							<p><span class="image right"><img style="width:6em;padding-left:0.5em;padding-top:.7em;" src="images/aaai-logo.png" alt="" /></span>
							The XAI4Sci: Explainable machine learning for sciences 2023 workshop will be held on February 26 or 27, 2024 at the at the Vancouver 
							Convention Centre &mdash; West Building in Vancouver, British Columbia, Canada as a part of the <a href="https://aaai.org/aaai-conference/">
							38th AAAI Conference on Artificial Intelligence</a> (AAAI-24). The AAAI-24 and all workshops are expected to take place in-person.

						</div>
					</section>

				<!-- Schedule -->
					<section id="schedule" class="three">
						<div class="container">

							<header>
								<h2>Schedule</h2>
							</header>

							<h3>Invited speakers</h3>
								<ul>
								<li>Katharina Beckh (Fraunhofer Institute for Intelligent Analysis and Information Systems)</li>
								
								<li><a href="https://www.physics.wisc.edu/directory/cranmer-kyle/">Kyle Cranmer</a> (Physics Department, University of Wisconsin-Madison)</li>
								
								<li><a hrf="https://people.llnl.gov/hiszpanski2">Anna M. Hiszpanski</a> (Materials Science Division, Lawrence Livermore National Laboratory) <br>
								<button type="button" class="collapse">Approaches for Explainability and Understanding in Machine Learning Applied to Materials Science</button> 
								<div class="content"> 
									<p style="margin-bottom:10px; padding: 0px;">TBA</p>
								</div>  </li>
								
								<li>Yue Shi Lai (Nuclear Science Division, Lawrence Berkeley National Laboratory)</li>
								
								<li><a href="https://www.pontzen.co.uk/">Andrew Pontzen</a> (Department of Physics and Astronomy, University College London)</li>
								
								<li><a href="http://www.aaswathraman.com/">Aaswath P. Raman</a> (Samueli School of Engineering, University of California Los Angeles) <br>								 
								<button type="button" class="collapse">Explainable AI to both elucidate and optimize the design of complex optical materials and devices</button> 
								<div class="content"> 
									<p style="margin-bottom:10px; padding: 0px;">Over the last thirty years the newly emerging fields of nanophotonics and metamaterials have 
									introduced new approaches to designing artificial materials that respond to electromagnetic waves in highly unusual ways, not achievable using 
									naturally accessible materials. This in turn has enabled a range of new device capabilities, including high-precision optical sensors, photonic 
									integrated circuits, new coatings for energy applications, and even exotic possibilities like invisibility cloaks. These unusual capabilities 
									arise from the ability to take conventional materials and by structuring or patterning them at length-scales that are either similar to, or 
									significantly smaller than, the wavelength of light one wishes to interact with. </p>

									<p style="margin:0px; padding-top:0px; margin-bottom: 10px;">In this context, a range of optimization and machine learning approaches have been 
									demonstrated to serve both as surrogate solvers that take a nanophotonic design and predict its optical response, as well as for inverse design, 
									where a nanophotonic design is optimized given an input target optical response. However, a fundamental challenge has emerged: the complex designs 
									that arise from these inverse design approaches can work well, but it is difficult to understand why they work and to further advance basic 
									understanding in the field. In this talk, I will introduce our work on using explainable AI approaches to both uncover why complex, often freeform, 
									structured material shapes are able to deliver particular optical responses. Additionally, I will show how an explainable AI approach (Deep SHAP) can 
									allow us to both understand the landscape navigated a conventional optimization algorithm, and to enhance its ability to perform inverse design. I 
									will conclude by discussing the potential for explainable AI approaches in the physical sciences more broadly, and how they might integrate with 
									physics-informed approaches such as PINNs to enable both improved optimization as well as scientific discovery.</p>
								</div>  </li>
								
								<li><a href="http://rs.ipb.uni-bonn.de/people/prof-dr-ing-ribana-roscher/">Ribana Roscher</a> (Institute of Geodesy and Geoinformation, University of Bonn)<br>
								<button type="button" class="collapse">Explain it to me! On the use of explainable machine learning for the agricultural and environmental sciences</button> 
								<div class="content"> 
									<p style="margin-bottom:10px; padding: 0px;">Machine learning approaches, especially deep neural networks, are showing tremendous success in finding 
									patterns and relationships in large data sets for predictions and classifications that are usually too complex to be directly captured by humans. In 
									addition to high accuracy, a desired goal is to learn explainable models and understand how a particular decision was made. To achieve this goal and 
									obtain explanations, knowledge from the domain is needed that is integrated into the model or applied post-hoc. This talk presents diverse environmental 
									and agricultural sciences applications in which explainable machine learning is used. It will also show that machine learning can not only be used to 
									learn models that align with our existing knowledge but can also lead to new scientific insights.</p>
								</div>  </li>
								
								<li><a href="https://users.cs.duke.edu/~cynthia/">Cynthia Rudin</a> (Department of Electrical and Computer Engineering, Duke University)</li>
								
								<li><a href="https://merowech.github.io/">Udo Schlegel</a> (Department of Computer and Information Science, Universit&auml;t Konstanz)</li>
								</ul>
								
								<script> 
									var coll = document.getElementsByClassName("collapse");
									var i;

									for (i = 0; i < coll.length; i++) {
									coll[i].addEventListener("click", function() {
										this.classList.toggle("active");
										var content = this.nextElementSibling;
										if (content.style.display === "block") {
										content.style.display = "none";
										} else {
										content.style.display = "block";
										}
									});
									}

								</script>
						</div>
					</section>

				<!-- Call for papers -->
					<section id="papers" class="two">
						<div class="container">

							<header>
								<h2>Call for papers</h2>
							</header>

							<p>The XAI4Sci Workshop Proceedings (XAI4Sci Proceedings) is the written record of the scholarly work presented at the XAI4Sci: Explainable Machine 
							Learning for Sciences workshop. The proceedings cover the full range of experimental and theoretical research on applications of explainable machine 
							learning techniques to real-world problems in sciences, including but not limited to, physics, materials science, earth science, cosmology, biology, 
							chemistry, medicine, and forensic science; explainable machine learning; and applied machine learning.
							</p>	

							<h3>Submission instructions</h3>
							<p>The organizers welcome submissions of significant or final results as well as preliminary research results and discussions of works in progress. 
							The short conference papers (extended abstracts) should be up to 4 pages in length (excluding acknowledgments and references). The authors should 
							follow the guidelines and best practices from the AAAI conference (see the main <a href="https://aaai.org/aaai-conference/aaai-24-call-for-proposals/">
							conference website</a> for additional information). Also, please ensure that your paper is accessible to someone who is not an expert in your specific 
							research area. When preparing your manuscript, please use the LaTeX AAAI paper template (available <a href="https://xai4sci.github.io/resources/AuthorKit24.zip">
							here</a>). Please, make sure to include the additional <a href="https://xai4sci.github.io/resources/paper_info.docx">information sheet</a> with your 
							submission. We reserve the right to desk-reject submissions that do not conform to the required format or do not provide all required information. To
							submit your work, use the <a href="https://openreview.net/group?id=AAAI.org/2024/Workshop/XAI4Sci">OpenReview portal</a>.</p>

							<h3>Review process and publication</h3>
							<p>All contributed manuscripts will undergo a double-blind peer-review process. For each submitted paper the authors will be required to indicate 
							at least one person from the authors list who will serve as a reviewer. The reviewers will be asked to review three papers submitted to the workshop. 
							The accepted papers will be published on the workshop website. We will provide the camera-ready LaTeX source to all accepted authors. Authors of 
							selected papers submitted to the workshop will be invited to submit a full research paper for consideration in a special issue in 
							<a href="https://iopscience.iop.org/journal/2632-2153">Machine Learning: Science and Technology</a> focusing on explainable machine learning in sciences.</p>

							<h3>Publication FAQ</h3>
							<ul>
								<li style="font-weight: bold;">Q: Is the paper published in any proceedings?</li>
								<li style="list-style: none">A: All accepted papers will be hosted on the workshp website. In addition, we are discussing publishing a special focused
								issue in <a href="https://iopscience.iop.org/journal/2632-2153">Machine Learning: Science and Technology</a> where authors of select papers submitted 
								to the workshop would be invited to submit a full research paper.</li>
								<li style="font-weight: bold;">Q: Is there any additional cost associated with the acceptance of my paper?</li>
								<li style="list-style: none">No, there are no additional costs associated with our workshop. However, since the workshop is hosted by AAAI, all participants 
								must be registered for the AAAI-24 to attend the workshop talks and the poster sessions.</li>
							</ul>							
								
					</div>
				</section>

				<!-- Contact -->
					<section id="organizers" class="four">
						<div class="container">

							<header>
								<h2>Organizers</h2>
							</header>

							<ul class="features">
								<li>
									<img style="width:10em;" src="images/JPZ.png" alt=""/>
									<h3><a href="https://www.nist.gov/people/justyna-zwolak">Justyna Zwolak</a></br>NIST</h3>
								</li>
								<li>
									<img style="width:10em;" src="images/CSG.png" alt=""/>
									<h3><a href="https://www.nist.gov/people/craig-greenberg">Craig Greenberg</a></br>NIST</h3>
								</li>
								<li>
									<img style="width:10em;" src="images/RC.png" alt=""/>
									<h3><a href="http://theoryandpractice.org/">Rich Caruana</a></br> Microsoft Research</h3>
								</li>
							</ul>

						

						</div>
					</section>

			</div>

		<!-- Footer -->
			<div id="footer">
				<p>For questions and comments, please contact: <a href="mailto:xai4sci2024@gmail.com">xai4sci2024@gmail.com</a></p>

			<!-- Copyright -->
				<ul class="copyright">
					<li>Copyright &copy; XAI4Sci.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
				</ul>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>